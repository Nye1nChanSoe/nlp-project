{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09073ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install spacy\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec1ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278ea757-0cfc-47eb-b405-d5a7bc094613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd72864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "path = kagglehub.dataset_download(\"rmisra/news-category-dataset\")\n",
    "\n",
    "print(os.listdir(path))\n",
    "file_path = os.path.join(path, \"News_Category_Dataset_v3.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6898b1d8-fcfe-4271-92f4-9cc9d517ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0efee8f-af45-4276-a7fe-2c6631d74b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(df['category'])\n",
    "counter.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bffd91-81b7-4266-98ae-b9c77ffc5435",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cats = [cat for cat, i in counter.most_common(6)] + [\"SPORTS\"]\n",
    "df = df[df[\"category\"].isin(top_cats)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142c7554-093e-4fbb-9593-ec4d449593a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = {cat:idx for idx, cat in enumerate(df['category'].unique())}\n",
    "CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be470007-de7a-46b4-a0c3-3003b4732742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['category'].map(CATEGORIES)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76b3780-33a9-492a-890b-b70d3f5c99ff",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eee805",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d9d83-c4d7-49b6-9b67-e5bd97ffbc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from typing import List\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6253f-86b3-4b2c-8fe1-f08229dce695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(headline: str) -> List[str]:\n",
    "    doc = nlp(headline)\n",
    "    return [\n",
    "        token.text.lower()\n",
    "        for token in doc\n",
    "        if not token.is_punct and token.is_alpha\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4de5c9-b503-4ed6-a3d2-b46025970e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['headline_tokens'] = df['headline'].progress_apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00d661-5016-4b60-905e-69f536f1d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description_tokens'] = df['short_description'].progress_apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5790de70-a953-4781-b4c4-e98cbbce31f1",
   "metadata": {},
   "source": [
    "# Prepare embeddings (GLOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdec681-52f2-4f54-b35c-17eb84f4e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de8eda-64ba-45b8-80ae-3c06b8da5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "wv = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47ec708-1cf9-4505-9c50-d4b93c7e73ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMB_DIM = wv.vector_size\n",
    "# UNK_VEC = np.zeros(EMB_DIM, dtype=\"float32\")\n",
    "# VOCAB = set(wv.index_to_key)\n",
    "\n",
    "# def vectorize(tokens: List[str]) -> torch.Tensor:\n",
    "#     vecs = [wv[token] for token in tokens if token in VOCAB]\n",
    "#     if not vecs:\n",
    "#         return torch.from_numpy(UNK_VEC)\n",
    "    \n",
    "#     mean_vec = np.mean(vecs, axis=0).astype(\"float32\")\n",
    "#     return torch.from_numpy(mean_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0133c4b-bfec-439e-ade1-1bf4ae5c70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = wv.vector_size\n",
    "\n",
    "counter = Counter(t for tokens in df[\"description_tokens\"] for t in tokens)\n",
    "vocab = {\"<PAD>\":0, # If we need to get specific batch size, but have not enough words in the sentence\n",
    "         \"<UNK>\":1}\n",
    "for token, freq in counter.items():\n",
    "      vocab[token] = len(vocab) # setting unique ID to each token in vocabulary\n",
    "PAD_IDX, UNK_IDX = 0, 1\n",
    "\n",
    "emb_matrix = np.random.normal(scale=0.6, size=(len(vocab), EMB_DIM)).astype(\"float32\")\n",
    "emb_matrix[PAD_IDX] = np.zeros(EMB_DIM)\n",
    "emb_matrix[UNK_IDX] = np.zeros(EMB_DIM)\n",
    "for token, idx in vocab.items():\n",
    "    # check if the token exists in word2vec\n",
    "    # add the line in the embedding matrix as vector for this token\n",
    "    if token in wv:\n",
    "        emb_matrix[idx] = wv[token]\n",
    "\n",
    "def transform_to_indices(tokens):\n",
    "    return [vocab.get(token) for token in tokens]\n",
    "\n",
    "df[\"description_indices\"] = df[\"description_tokens\"].progress_apply(transform_to_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14417c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf48845-b5f3-4b46-89bc-46eba446a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['headline_vector'] = df['headline_tokens'].progress_apply(vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eec130-b890-4269-a984-ff9a03931c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['description_vector'] = df['description_tokens'].progress_apply(vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1375b8-9732-4d29-b838-2d5488db1538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33148b-cb05-4f09-8e72-4f8aceefa365",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a521693b-1f49-4170-aa7e-2de20e87a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93f7095-3fbe-4aa1-95d2-8534ac607a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, emb_dim: int, n_classes: int, hidden_dim: int = 64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d58f77-e86b-4c8b-b3eb-e377aec74d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMAttentionClassifier(nn.Module):\n",
    "    def __init__(self, emb_matrix, n_classes, freeze, hidden=128, num_layers=1, bidirectional=True, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.hidden_size = hidden\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(emb_matrix),\n",
    "            freeze=freeze\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=emb_matrix.shape[1],\n",
    "            hidden_size=hidden,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "        self.attention = nn.Linear(hidden * self.num_directions, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden * self.num_directions, n_classes)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        emb = self.embedding(x)\n",
    "\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.lstm(packed)\n",
    "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "\n",
    "        attn_weights = self.attention(lstm_out)\n",
    "        attn_weights = torch.softmax(attn_weights.squeeze(-1), dim=1).unsqueeze(-1)\n",
    "\n",
    "        context = torch.sum(lstm_out * attn_weights, dim=1)\n",
    "\n",
    "        out = self.dropout(context)\n",
    "        logits = self.fc(out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff9ca3-29d0-4b31-8311-0951a901ce92",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c57e1f-59be-4db3-87f8-f3ca1005524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c0bfe1-0fac-4288-b4f2-130a4ea05965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, vecs, labels):\n",
    "#         self.vecs = vecs\n",
    "#         self.labels = labels\n",
    "#     def __len__(self):\n",
    "#         return len(self.vecs)\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.vecs[idx], self.labels[idx]\n",
    "\n",
    "# # dataset = CustomDataset(df[\"headline_vector\"].tolist(), df[\"label\"].tolist())\n",
    "# dataset = CustomDataset(df[\"description_vector\"].tolist(), df[\"label\"].tolist())\n",
    "# train_size = int(0.8*len(dataset))\n",
    "# val_size = len(dataset) - train_size\n",
    "# train_ds, val_ds = random_split(dataset, [train_size, val_size],\n",
    "#                                 generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "# val_dl = DataLoader(val_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712435fe-bd00-4ebb-b4e5-2ba472d9132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['description_indices'].apply(lambda x: len(x) > 0)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c4c956-a961-4780-9659-462cbfe6ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "# Создаём списки\n",
    "X = df[\"description_indices\"].tolist()\n",
    "y = df[\"label\"].tolist()\n",
    "\n",
    "# Stratified split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Кастомный Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, idxs, labels):\n",
    "        self.idxs = idxs\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.idxs[idx], self.labels[idx]\n",
    "\n",
    "# Функция паддинга\n",
    "def pad(batch):\n",
    "    idxs, labels = zip(*batch)\n",
    "    idxs = [torch.tensor(idx, dtype=torch.long) for idx in idxs]\n",
    "    lens = torch.tensor([len(idx) for idx in idxs], dtype=torch.long)\n",
    "    pads = pad_sequence(idxs, batch_first=True, padding_value=PAD_IDX)\n",
    "    return pads, torch.tensor(labels, dtype=torch.float32), lens\n",
    "\n",
    "# Создание датасетов и загрузчиков\n",
    "train_ds = CustomDataset(X_train, y_train)\n",
    "val_ds = CustomDataset(X_val, y_val)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=pad)\n",
    "val_dl = DataLoader(val_ds, batch_size=64, shuffle=False, collate_fn=pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca32c5ee-3210-4eb6-8a72-97eec21d18ba",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a83107-d25c-49f9-8348-2d55fe8af757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884bf10f-b5c3-4aff-b5f6-8c8967a336ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d861f-b78f-4fdd-a581-aa20f52e8008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "# model = FFNN(EMB_DIM, len(CATEGORIES), hidden_dim=256)\n",
    "# optimizer = Adam(model.parameters())\n",
    "\n",
    "# loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adbbfce-54bb-45a9-9c40-a27316949c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 20\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#     epoch_losses = 0\n",
    "    \n",
    "#     model.train()\n",
    "#     for X, y in train_dl:\n",
    "#         y = y.to(device).long()\n",
    "#         X = X.to(device).float()\n",
    "#         optimizer.zero_grad()\n",
    "#         out = model(X)\n",
    "#         loss = loss_function(out, y)\n",
    "#         epoch_losses += loss.detach().cpu().item()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#     print(\"Loss function:\", epoch_losses / len(train_dl))\n",
    "\n",
    "#     model.eval()\n",
    "#     preds, true_labels = [], []\n",
    "#     with torch.no_grad():\n",
    "#         for X, y in val_dl:\n",
    "#             X = X.to(device).float()\n",
    "#             logits = model(X)\n",
    "#             probs = torch.softmax(logits, dim=1).cpu()\n",
    "#             preds.extend(torch.argmax(probs, dim=1).cpu().numpy())\n",
    "#             true_labels.extend(y.numpy())\n",
    "\n",
    "#     acc = accuracy_score(true_labels, preds)\n",
    "#     p, r, f1, _ = precision_recall_fscore_support(true_labels, preds, average=\"macro\")\n",
    "#     if epoch % 5 == 0:\n",
    "#         print(f\"Epoch {epoch:02d} | Acc {acc:.3f} · P {p:.3f} · R {r:.3f} · F1 {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964071a8-12d5-4e9c-8620-13b47a2a53c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(emb_matrix, len(CATEGORIES), False, num_layers=2)\n",
    "optimizer = Adam(model.parameters())\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f5716-aaa4-461f-853a-5c746d509f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "best_f1 = 0.0\n",
    "best_model_path = \"best_model.pt\"\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_losses = 0\n",
    "    model.train()\n",
    "\n",
    "    for X, y, lengths in train_dl:\n",
    "        X = X.to(device).long()\n",
    "        y = y.to(device).long()\n",
    "        lengths = lengths.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(X, lengths)\n",
    "        loss = loss_function(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses += loss.item() * X.size(0)\n",
    "\n",
    "    avg_loss = epoch_losses / len(train_dl.dataset)\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y, lengths in val_dl:\n",
    "            X = X.to(device).long()\n",
    "            y = y.to(device).long()\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            logits = model(X, lengths)\n",
    "            pred_labels = torch.argmax(torch.softmax(logits, dim=1), dim=1)\n",
    "\n",
    "            preds.extend(pred_labels.cpu().numpy())\n",
    "            true_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(true_labels, preds)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(true_labels, preds, average=\"macro\")\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Saved new best model at epoch {epoch:02d} with F1 = {f1:.3f}\")\n",
    "\n",
    "    if epoch % 2 == 0 or epoch == EPOCHS - 1:\n",
    "        print(f\"Eval  | Acc {acc:.3f} · P {p:.3f} · R {r:.3f} · F1 {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce68ee8-8282-48c6-bf5a-44206c1200e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def predict_category(text: str, model, vocab, categories, device, tokenize, PAD_IDX=0):\n",
    "    model.eval()\n",
    "    tokens = tokenize(text)\n",
    "\n",
    "    if len(tokens) == 0:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    indices = [vocab.get(token, vocab.get(\"<UNK>\", 1)) for token in tokens]\n",
    "    tensor = torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(device)  # [1, seq_len]\n",
    "    lengths = torch.tensor([len(indices)]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(tensor, lengths)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        predicted_class = torch.argmax(probs, dim=1).item()\n",
    "\n",
    "    return categories[predicted_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1f3374-c0f0-4499-80d9-c30b5cc4ceb2",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920fb1b2-f840-4a0d-86c6-0426db5a3fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(emb_matrix, len(CATEGORIES), False, num_layers=2)\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e52b720-9c2c-4568-8e8e-d7cb107ffa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inv_cats = {  }\n",
    "inv_cats = {idx:word for idx, word in enumerate(CATEGORIES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541fde8-6596-4f3e-91fb-646b7112f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = [\n",
    "    \"President addresses the nation on upcoming policy changes and budget reforms.\",\n",
    "    \"10 mindfulness techniques to reduce daily stress and improve sleep.\",\n",
    "    \"Top 5 destinations in Europe to visit this summer on a budget.\",\n",
    "    \"Actor surprises fans with unexpected appearance at film festival.\",\n",
    "    \"Senate debates controversial law affecting voting rights across states.\",\n",
    "    \"Healthy breakfast recipes to kickstart your metabolism every morning.\",\n",
    "    \"Behind the scenes of the latest Hollywood blockbuster release.\",\n",
    "    \"Best hiking trails in Southeast Asia for nature lovers and adventurers.\",\n",
    "    \"Government releases new guidelines for international trade relations.\",\n",
    "    \"Yoga and breathing exercises that can ease anxiety and boost focus.\",\n",
    "    \"Trump's voters want to see the Epstein files - but have faith in their president\",\n",
    "    \"Hidden in a quiet Italian town is one of the world's most unique art schools – and a rewarding destination for curious travellers.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72dacd0-fa10-4eb7-b4db-2e3a5cc5a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "for desc in descriptions:\n",
    "    predicted = predict_category(\n",
    "        desc,\n",
    "        model=model,\n",
    "        vocab=vocab,\n",
    "        categories=inv_cats,\n",
    "        device=device,\n",
    "        tokenize=tokenize,\n",
    "        PAD_IDX=PAD_IDX\n",
    "    )\n",
    "    print(\"Description:\", desc)\n",
    "    print(\"Predicted category:\", predicted)\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b95d64-4147-4bef-8804-7641ba49f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "descs = [\n",
    "    # PARENTING\n",
    "    \"Tips for new parents to help toddlers sleep through the night.\",\n",
    "    \"How to talk to your teenager about social media and mental health.\",\n",
    "\n",
    "    # ENTERTAINMENT\n",
    "    \"A behind-the-scenes look at the latest Marvel movie production.\",\n",
    "    \"Famous pop singer drops surprise album and breaks streaming records.\",\n",
    "\n",
    "    # POLITICS\n",
    "    \"The Senate passes a new climate bill after weeks of negotiations.\",\n",
    "    \"President addresses economic recovery in latest press conference.\",\n",
    "\n",
    "    # WELLNESS\n",
    "    \"10 easy yoga poses to reduce anxiety and improve posture.\",\n",
    "    \"Experts share strategies to maintain emotional well-being during winter.\",\n",
    "\n",
    "    # STYLE & BEAUTY\n",
    "    \"Fall fashion trends to refresh your wardrobe this season.\",\n",
    "    \"The rise of sustainable beauty brands in the cosmetics industry.\",\n",
    "    \"Ready to refresh your wardrobe for this summer with the president of the USA?\",\n",
    "\n",
    "    # TRAVEL\n",
    "    \"Top 10 hidden islands to explore in Southeast Asia.\",\n",
    "    \"A guide to experiencing Paris like a local on a weekend trip.\"\n",
    "]\n",
    "\n",
    "\n",
    "for desc in descs:\n",
    "    predicted = predict_category(\n",
    "        desc,\n",
    "        model=model,\n",
    "        vocab=vocab,\n",
    "        categories=inv_cats,\n",
    "        device=device,\n",
    "        tokenize=tokenize,\n",
    "        PAD_IDX=PAD_IDX\n",
    "    )\n",
    "    print(\"Description:\", desc)\n",
    "    print(\"Predicted category:\", predicted)\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bfc306-d671-4134-998a-fb6f815cff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276fbcd7-aef1-4e7a-b020-b9ca3feba829",
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_descriptions = [\n",
    "    \"Local football team wins the championship after dramatic penalty shootout.\",\n",
    "    \"Olympic sprinter sets new world record in 100-meter dash.\",\n",
    "    \"Top 10 workouts professional athletes use to stay in peak condition.\",\n",
    "    \"Basketball legend announces retirement after two decades in the sport.\",\n",
    "    \"How to train for your first marathon: tips from elite runners.\",\n",
    "    \"The science behind muscle recovery and post-workout nutrition.\",\n",
    "    \"Why yoga is becoming a staple in NFL players' training routines.\",\n",
    "    \"Highlights from last night's thrilling NBA playoff game.\",\n",
    "    \"How mental resilience separates top athletes from the rest.\",\n",
    "    \"Teen gymnast stuns judges with flawless Olympic routine.\"\n",
    "]\n",
    "\n",
    "for desc in sports_descriptions:\n",
    "    predicted = predict_category(\n",
    "        desc,\n",
    "        model=model,\n",
    "        vocab=vocab,\n",
    "        categories=inv_cats,\n",
    "        device=device,\n",
    "        tokenize=tokenize,\n",
    "        PAD_IDX=PAD_IDX\n",
    "    )\n",
    "    print(\"Description:\", desc)\n",
    "    print(\"Predicted category:\", predicted)\n",
    "    print(\"-----------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
